{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Associated words.xlsx'     'Text mining word list test 200823.xlsx'\r\n",
      " cordis-h2020projects.xlsx   topics_300_SYinput_LW.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import sample, shuffle\n",
    "import pickle\n",
    "\n",
    "from gensim.models.wrappers import ldamallet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/kohkb/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/kohkb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src.artefacts_helper import load_mallet_model\n",
    "from src.gensim_helper import create_dictionary, get_coherence\n",
    "from src.artefacts_helper import save_model\n",
    "from src.process_data import process_data\n",
    "from src.train import train_lda_mallet\n",
    "from src.predict import get_all_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30084, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheets_dict = pd.read_excel('../data/cordis-h2020projects.xlsx', None)\n",
    "df = sheets_dict['cordis-h2020projects']\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 22552\n",
      "Number of documents: 30084\n"
     ]
    }
   ],
   "source": [
    "# combine title and objective\n",
    "data = (df['title'] + ' ' + df['objective']).values.tolist()\n",
    "docs = process_data(data)\n",
    "dictionary = create_dictionary(docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in docs]\n",
    "\n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Id</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "      <th>Relevance (SY)</th>\n",
       "      <th>LW comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>political, study, social, politics, discourse,...</td>\n",
       "      <td>249.0</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>disease, inflammatory, inflammation, therapeut...</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>delivery, release, deliver, based, develop, oa...</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>emission, fuel, gas, co2, carbon, reduction, c...</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>liver, development, sport, aim, major, event, ...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Id                                     Topic_Keywords  Num_Documents  \\\n",
       "0         0  political, study, social, politics, discourse,...          249.0   \n",
       "1         1  disease, inflammatory, inflammation, therapeut...          122.0   \n",
       "2         2  delivery, release, deliver, based, develop, oa...           55.0   \n",
       "3         3  emission, fuel, gas, co2, carbon, reduction, c...          211.0   \n",
       "4         4  liver, development, sport, aim, major, event, ...           47.0   \n",
       "\n",
       "   Perc_Documents Relevance (SY)  LW comments  \n",
       "0          0.0083             No          NaN  \n",
       "1          0.0041            Yes          NaN  \n",
       "2          0.0018            Yes          NaN  \n",
       "3          0.0070             No          NaN  \n",
       "4          0.0016            Yes          NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_topics_df = pd.read_csv('../data/topics_300_SYinput_LW.csv')\n",
    "labelled_topics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     197\n",
       "Yes     99\n",
       "NO       2\n",
       "no       1\n",
       "yes      1\n",
       "Name: Relevance (SY), dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_topics_df['Relevance (SY)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    200\n",
       "True     100\n",
       "Name: Relevance (SY), dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_topics_df['Relevance (SY)'] = [i.strip().lower() == 'yes' for i in labelled_topics_df['Relevance (SY)']]\n",
    "labelled_topics_df['Relevance (SY)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5, 7]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_topics = set(labelled_topics_df[labelled_topics_df['Relevance (SY)']]['Topic_Id'].values.tolist())\n",
    "list(relevant_topics)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = load_mallet_model(artefacts_path='../artefacts', suffix='300_topics_mallet_alpha_50')\n",
    "model.mallet_path = '../mallet-2.0.8/bin/mallet'\n",
    "model.prefix = '../artefacts/mallet_tmp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 3.53 s, total: 1min 7s\n",
      "Wall time: 9min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5301726081250121"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# for reproducibility: 0.5301726081250121\n",
    "get_coherence(model, docs, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__If a document does not have any relevant topics in its top n topics, remove it__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original corpus size: 30084\n",
      "filtered corpus size: 23029\n"
     ]
    }
   ],
   "source": [
    "print('original corpus size:', len(corpus))\n",
    "filtered_doc_id = []\n",
    "top_topics = 5\n",
    "\n",
    "for idx, i in enumerate(predictions):\n",
    "    top_n_topics = set([j[0] for j in sorted(i, key=lambda x: x[1], reverse=True)[:top_topics]])\n",
    "    if top_n_topics.intersection(relevant_topics) != set():\n",
    "        filtered_doc_id.append(idx)\n",
    "\n",
    "print('filtered corpus size:', len(filtered_doc_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original corpus size: 30084\n",
      "filtered corpus size: 19702\n"
     ]
    }
   ],
   "source": [
    "print('original corpus size:', len(corpus))\n",
    "filtered_doc_id = []\n",
    "top_topics = 3\n",
    "\n",
    "for idx, i in enumerate(predictions):\n",
    "    top_n_topics = set([j[0] for j in sorted(i, key=lambda x: x[1], reverse=True)[:top_topics]])\n",
    "    if top_n_topics.intersection(relevant_topics) != set():\n",
    "        filtered_doc_id.append(idx)\n",
    "\n",
    "print('filtered corpus size:', len(filtered_doc_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original corpus size: 30084\n",
      "filtered corpus size: 13086\n"
     ]
    }
   ],
   "source": [
    "print('original corpus size:', len(corpus))\n",
    "filtered_doc_id = []\n",
    "top_topics = 1\n",
    "\n",
    "for idx, i in enumerate(predictions):\n",
    "    top_n_topics = set([j[0] for j in sorted(i, key=lambda x: x[1], reverse=True)[:top_topics]])\n",
    "    if top_n_topics.intersection(relevant_topics) != set():\n",
    "        filtered_doc_id.append(idx)\n",
    "\n",
    "print('filtered corpus size:', len(filtered_doc_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Filtering by threshold__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original corpus size: 30084\n",
      "filtered corpus size: 10572\n"
     ]
    }
   ],
   "source": [
    "print('original corpus size:', len(corpus))\n",
    "filtered_doc_id = []\n",
    "top_topics = 1\n",
    "prob_threshold = 0.1\n",
    "\n",
    "for idx, i in enumerate(predictions):\n",
    "    top_n_topics = set([j[0] for j in sorted(i, key=lambda x: x[1], reverse=True)[:top_topics] if j[1] >= prob_threshold])\n",
    "    if top_n_topics.intersection(relevant_topics) != set():\n",
    "        filtered_doc_id.append(idx)\n",
    "\n",
    "print('filtered corpus size:', len(filtered_doc_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since using `top_topics` = 1 since to work well, current filtering method will be that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Sampling Filtered Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame([(i, data[i]) for i in sample(filtered_doc_id, 100)], columns=['doc_id', 'data']).to_csv('../output/temp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eyeballing some keywords¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_keyword_stats(docs, filtered_doc_id, keyword):\n",
    "    print(f'keyword: {keyword}')\n",
    "    keyword_ids = set([idx for idx, i in enumerate(docs) if keyword in i])\n",
    "    print(f'number of unique documents with \\'{keyword}\\': {len(keyword_ids)}')\n",
    "    num_intersection = len(set(filtered_doc_id).intersection(keyword_ids))\n",
    "    print(f'number of intersection with filtered corpus: {num_intersection} = {round(num_intersection/len(keyword_ids), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: crispr\n",
      "number of unique documents with 'crispr': 258\n",
      "number of intersection with filtered corpus: 246 = 0.9535\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'crispr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: cas9\n",
      "number of unique documents with 'cas9': 164\n",
      "number of intersection with filtered corpus: 158 = 0.9634\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'cas9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: rna\n",
      "number of unique documents with 'rna': 610\n",
      "number of intersection with filtered corpus: 580 = 0.9508\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'rna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: mrna\n",
      "number of unique documents with 'mrna': 168\n",
      "number of intersection with filtered corpus: 164 = 0.9762\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'mrna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: cancer\n",
      "number of unique documents with 'cancer': 1831\n",
      "number of intersection with filtered corpus: 1658 = 0.9055\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: vaccine\n",
      "number of unique documents with 'vaccine': 290\n",
      "number of intersection with filtered corpus: 257 = 0.8862\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'vaccine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: alzheimer\n",
      "number of unique documents with 'alzheimer': 236\n",
      "number of intersection with filtered corpus: 213 = 0.9025\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'alzheimer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: insulin\n",
      "number of unique documents with 'insulin': 116\n",
      "number of intersection with filtered corpus: 111 = 0.9569\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'insulin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: diabetes\n",
      "number of unique documents with 'diabetes': 391\n",
      "number of intersection with filtered corpus: 355 = 0.9079\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: gene\n",
      "number of unique documents with 'gene': 1633\n",
      "number of intersection with filtered corpus: 1520 = 0.9308\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: bacteria\n",
      "number of unique documents with 'bacteria': 643\n",
      "number of intersection with filtered corpus: 508 = 0.79\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'bacteria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: leukemia\n",
      "number of unique documents with 'leukemia': 84\n",
      "number of intersection with filtered corpus: 79 = 0.9405\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'leukemia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword: immunotherapy\n",
      "number of unique documents with 'immunotherapy': 208\n",
      "number of intersection with filtered corpus: 198 = 0.9519\n"
     ]
    }
   ],
   "source": [
    "display_keyword_stats(docs, filtered_doc_id, 'immunotherapy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Save Artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13086"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = [i for idx, i in enumerate(data) if idx in filtered_doc_id]\n",
    "filtered_docs = [i for idx, i in enumerate(docs) if idx in filtered_doc_id]\n",
    "len(filtered_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filtered_dict = create_dictionary(filtered_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Bag-of-words representation of the documents.\n",
    "filtered_corpus = [filtered_dict.doc2bow(doc) for doc in filtered_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# other artefacts\n",
    "filtered_dict.save('../artefacts/filtered_top_1_dictionary')\n",
    "\n",
    "with open('../artefacts/filtered_top_1_docs.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_docs, f)\n",
    "\n",
    "with open('../artefacts/filtered_top_doc_id.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_doc_id, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.45 s, sys: 100 ms, total: 7.55 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "filtered_model = train_lda_mallet(filtered_corpus, filtered_dict, 300, \n",
    "                         params={\n",
    "                             'mallet_path': '../mallet-2.0.8/bin/mallet',\n",
    "                             'prefix_path': '../artefacts/mallet_tmp/',\n",
    "                             'prefix': 'filtered_top_1'\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Id</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>circuit, brain, neuron, cortical, cortex, acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>child, adult, young, parent, study, childhood,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>process, multiple, stability, provide, stable,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>paradigm, bio, shift, goal, develop, breakthro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>function, regulation, homeostasis, role, regul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Id                                     Topic_Keywords\n",
       "0         0  circuit, brain, neuron, cortical, cortex, acti...\n",
       "1         1  child, adult, young, parent, study, childhood,...\n",
       "2         2  process, multiple, stability, provide, stable,...\n",
       "3         3  paradigm, bio, shift, goal, develop, breakthro...\n",
       "4         4  function, regulation, homeostasis, role, regul..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_topics(filtered_model).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.505769846580301"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for reproducibility, should be 0.505769846580301\n",
    "get_coherence(filtered_model, filtered_docs, filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved at ../artefacts/model_filtered_top_1\n"
     ]
    }
   ],
   "source": [
    "save_model(filtered_model, suffix='filtered_top_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "283px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
